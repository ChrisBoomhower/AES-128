{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis of AES-128\n",
    "#### Meenu Ahluwalia, Chris Boomhower, Steven Millett\n",
    "This Jupyter Notebook contains the code used to implement our AES-128 bias analysis for MSDS7349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# To install pycrypto module, run following from command line in PuTTy:  python3 /usr/local/es7/bin/pip3 install --user pycrypto\n",
    "from Crypto import Random\n",
    "from Crypto.Cipher import AES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Following code chunk obtained from https://stackoverflow.com/questions/12524994/encrypt-decrypt-using-pycrypto-aes-256/12525165#12525165\n",
    "\n",
    "BS = 16\n",
    "pad = lambda s: s + (BS - len(s) % BS) * chr(BS - len(s) % BS)\n",
    "unpad = lambda s : s[0:-s[-1]]\n",
    "\n",
    "\n",
    "class AESCipher:\n",
    "\n",
    "    def __init__( self, key ):\n",
    "        self.key = hashlib.sha256(key.encode('utf-8')).digest()\n",
    "\n",
    "    def encrypt( self, raw ):\n",
    "        raw = pad(raw)\n",
    "        iv = Random.new().read( AES.block_size )\n",
    "        cipher = AES.new( self.key, AES.MODE_CBC, iv )\n",
    "        return base64.b64encode( iv + cipher.encrypt( raw ) )\n",
    "\n",
    "    def decrypt( self, enc ):\n",
    "        enc = base64.b64decode(enc)\n",
    "        iv = enc[:16]\n",
    "        cipher = AES.new(self.key, AES.MODE_CBC, iv )\n",
    "        return unpad(cipher.decrypt( enc[16:] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at encryption and decryption using the above class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ovkTCLH09GUpcNCn9JVw1hE4+zDysvadjIYJY4V8LQnzMGtsO32BRt8O1Mm+B2yM'\n",
      "b'Super secret message'\n"
     ]
    }
   ],
   "source": [
    "cipher = AESCipher('mysecretpassword') #16-byte password\n",
    "encrypted = cipher.encrypt('Super secret message')\n",
    "decrypted = cipher.decrypt(encrypted)\n",
    "print(encrypted)\n",
    "print(decrypted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at how long it takes to generate 1 million cipher blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cipher = AESCipher('mysecretpassword') #16-byte password\n",
    "\n",
    "AES_list = []\n",
    "for x, i in enumerate(range(0,1000000)):\n",
    "    AES_list.append(cipher.encrypt('Super secret message %d' %i))\n",
    "\n",
    "dec_list = []\n",
    "for crypto in AES_list:\n",
    "    dec_list.append(cipher.decrypt(crypto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be working well...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for crypto in AES_list[:10]:\n",
    "    print(crypto)\n",
    "for msg in dec_list[:10]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(AES_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we can decipher the original messages just to ensure we have valid encryption..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'HtoKljOT9dU7InuKWQMA7xh4DLUHj8nx6D3UByRTIjc/ne67VR6dA+TK+ArAaEI5'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AES_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Super secret message 0'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test code already made available at following links:\n",
    "**https://gerhardt.ch/random.php may actually have everything we need.\n",
    "\n",
    "**This source may also have everything we need, test-by-test:  https://github.com/StuartGordonReid/r4nd0m**\n",
    "\n",
    "Other test-by-test resources:\n",
    "1. Frequency (Monobit) Test\n",
    "2. Frequency Test within a Block\n",
    "3. The Runs Test\n",
    "4. Tests for the Longest-Run-of-Ones in a Block\n",
    "5. The Binary Matrix Rank Test\n",
    "6. The Discrete Fourier Transform (Spectral) Test\n",
    "7. The Non-overlapping Template Matching Test\n",
    "8. The Overlapping Template Matching Test\n",
    "9. Maurer's \"Universal Statistical\" Test\n",
    "10. The Linear Complexity Test\n",
    "11. The Serial Test\n",
    "12. The Approximate Entropy Test - https://gist.github.com/StuartGordonReid/ff86c5a895fa90b0880e\n",
    "13. Cumulative Sums (Cusums) test - https://gist.github.com/StuartGordonReid/b9024c910e96d6649a88\n",
    "14. The Random Excursions Test - https://gist.github.com/StuartGordonReid/349af3d891e5832272ab\n",
    "15. The Random Excursions Variant Test - https://gist.github.com/StuartGordonReid/e2d036d9d90ac67f73c0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following are attempts to use r4nd0m's github library\n",
    "Below code chunk extracted from r4nd0m's github repo contents at https://github.com/StuartGordonReid/r4nd0m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.special as spc\n",
    "import scipy.fftpack as sff\n",
    "import scipy.stats as sst\n",
    "import numpy\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "\n",
    "class Colours:\n",
    "    \"\"\"\n",
    "    Just used to make the standard-out a little bit less ugly\n",
    "    \"\"\"\n",
    "    Pass, Fail, End, Bold, Info, Italics = '\\033[92m', '\\033[91m', '\\033[0m', '\\033[1m', '\\033[94m', '\\x1B[3m'\n",
    "    \n",
    "class RandomnessTester:\n",
    "    def __init__(self, bin, real_data=False, start_year=00, end_year=00):\n",
    "        \"\"\"\n",
    "        Initializes a RandomnessTester object. This object contains the NIST cryptographic tests for randomness [1].\n",
    "        These tests only work on binary strings. The input data (bin) is a BinaryFrame object. A BinaryFrame object is\n",
    "        simply a dictionary of lists containing binary strings. Each entry in the dictionary is an independent data set,\n",
    "        and each binary string in the list represents a different time period. For example,\n",
    "\n",
    "        bin.data = {    \"JSE\",      [010101010, 0111101111, 10101010000],\n",
    "                        \"S&P500\",   [000000000, 1111111111, 01010101010] ... }\n",
    "\n",
    "        Each binary string in the list is a sample. These samples are EACH fed through all of the NIST tests and their\n",
    "        respective p-values are calculated. If ~96% of samples pass, the data set passes the randomness test(s) e.g.\n",
    "\n",
    "        [1] For more information see - http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "        :param bin: this is a \"BinaryFrame\" object which is a conversion of a pandas DataFrame into a binary dictionary\n",
    "        \"\"\"\n",
    "        self.bin = bin\n",
    "        self.real_data = real_data\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.epsilon = 0.00001\n",
    "        self.confidence_level = 0.005\n",
    "\n",
    "    def get_string(self, p_val):\n",
    "        \"\"\"\n",
    "        This method returns a string based on the p-value\n",
    "        :param p_val: the p-value generated by a given test\n",
    "        :return: a string for outputting to the console\n",
    "        \"\"\"\n",
    "        if p_val >= 0:\n",
    "            if p_val < self.confidence_level:\n",
    "                return Colours.Fail + \"{0:.5f}\".format(p_val) + \"\\t\" + Colours.End\n",
    "            else:\n",
    "                return Colours.Pass + \"{0:.5f}\".format(p_val) + \"\\t\" + Colours.End\n",
    "        else:\n",
    "            return \"{0:.4f}\".format(p_val) + \"\\t\" + Colours.End\n",
    "\n",
    "    def get_aggregate_pval(self, pvals):\n",
    "        \"\"\"\n",
    "        This method applies a chi-squared test on a series of p-values to check their uniformity.\n",
    "        :param pvals: the list of p-values for a given data set across all the NIST tests\n",
    "        :return: the aggregate p-value based on the chi-squared test for the p values.\n",
    "        \"\"\"\n",
    "        bin_counts = numpy.zeros(10)\n",
    "        for p in pvals:\n",
    "            pos = min(int(math.floor(p * 10)), 9)\n",
    "            bin_counts[pos] += 1\n",
    "        chi_squared = 0\n",
    "        expected_count = len(pvals) / 10\n",
    "        for bin_count in bin_counts:\n",
    "            chi_squared += pow(bin_count - expected_count, 2.0) / expected_count\n",
    "        return spc.gammaincc(9.0 / 2.0, chi_squared / 2.0)\n",
    "\n",
    "    def get_aggregate_pass(self, pvals):\n",
    "        \"\"\"\n",
    "        This method determines if a data set passed when you look at all the p-values associates with each of the binary\n",
    "        strings associated with that data set. If the data set passes on ~96% of the samples it passes overall.\n",
    "        :param pvals: the list of p-values for a given data set across all the NIST tests\n",
    "        :return: the proportion of samples which passed their tests.\n",
    "        \"\"\"\n",
    "        npvals = numpy.array(pvals)\n",
    "        return (npvals > self.confidence_level).sum() / len(pvals)\n",
    "\n",
    "    def print_dates(self, num_blocks):\n",
    "        if self.real_data:\n",
    "            filler = \"\".zfill(68)\n",
    "            string_out = filler.replace(\"0\", \" \")\n",
    "            step = math.floor((self.end_year - self.start_year) / num_blocks)\n",
    "            dates = numpy.arange(start=self.start_year, stop=self.end_year, step=step)\n",
    "            for i in range(num_blocks):\n",
    "                start_string = \"~\" + str(int(dates[i]))\n",
    "                string_out += start_string + \"\\t\"\n",
    "            print(string_out)\n",
    "\n",
    "    def run_test_suite(self, block_size, matrix_size):\n",
    "        \"\"\"\n",
    "        This method runs all of the tests included in the NIST test suite for randomness\n",
    "        :param block_size: the length of each block to look at for each bit string\n",
    "        :param matrix_size: the size of the matrix to look at for each bit string\n",
    "        \"\"\"\n",
    "        tests_passed = []\n",
    "        # For each data set in self.bin\n",
    "        for c in self.bin.columns:\n",
    "            print(Colours.Bold + \"\\n\\tRunning \" + self.bin.method + \" based tests on\", c + Colours.End, \"\\n\")\n",
    "            test_names = [\"\\t01. Monobit Test\",\n",
    "                          \"\\t02. Block Frequency Test\",\n",
    "                          \"\\t03. Independent Runs Test\",\n",
    "                          \"\\t04. Longest Runs Test\",\n",
    "                          \"\\t05. Matrix Rank Test\",\n",
    "                          \"\\t06. Spectral Test\",\n",
    "                          \"\\t07. Non Overlapping Patterns Test\",\n",
    "                          \"\\t08. Overlapping Patterns Test\",\n",
    "                          \"\\t09. Universal Test\",\n",
    "                          \"\\t10. Linear Complexity Test\",\n",
    "                          \"\\t11. Serial Test (p01)\",\n",
    "                          \"\\t11. Serial Test (p02)\",\n",
    "                          \"\\t12. Approximate Entropy Test\",\n",
    "                          \"\\t13. Cumulative Sums Test (Forward)\",\n",
    "                          \"\\t13. Cumulative Sums Test (Backward)\",\n",
    "                          \"\\t14. Random Excursions Test (p01)\",\n",
    "                          \"\\t14. Random Excursions Test (p02)\",\n",
    "                          \"\\t14. Random Excursions Test (p03)\",\n",
    "                          \"\\t14. Random Excursions Test (p04)\",\n",
    "                          \"\\t14. Random Excursions Test (p05)\",\n",
    "                          \"\\t14. Random Excursions Test (906)\",\n",
    "                          \"\\t14. Random Excursions Test (p07)\",\n",
    "                          \"\\t14. Random Excursions Test (p08)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p01)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p02)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p03)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p04)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p05)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p06)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p07)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p08)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p09)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p10)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p11)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p12)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p13)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p14)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p15)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p16)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p17)\",\n",
    "                          \"\\t15. Random Excursions Variant Test (p18)\"]\n",
    "\n",
    "            pvals = []\n",
    "            pval_strings = []\n",
    "            for i in range(len(test_names)):\n",
    "                length = len(test_names[i])\n",
    "                space = 45 - length\n",
    "                filler = \"\".zfill(space)\n",
    "                filler = filler.replace(\"0\", \" \")\n",
    "                test_names[i] += filler\n",
    "                pvals.append([])\n",
    "                pval_strings.append(\"\")\n",
    "\n",
    "            # Get the samples for the data set\n",
    "            binary_strings = self.bin.bin_data[c]\n",
    "            # Run each one of the tests and record the p_values\n",
    "            for i in range(len(binary_strings)):\n",
    "                passed_values, p_values, str_data = [], [], binary_strings[i]\n",
    "\n",
    "                p_val = self.monobit(str_data)\n",
    "                pval_strings[0] += self.get_string(p_val)\n",
    "                pvals[0].append(p_val)\n",
    "\n",
    "                p_val = self.block_frequency(str_data, block_size=block_size)\n",
    "                pval_strings[1] += self.get_string(p_val)\n",
    "                pvals[1].append(p_val)\n",
    "\n",
    "                p_val = self.independent_runs(str_data)\n",
    "                pval_strings[2] += self.get_string(p_val)\n",
    "                pvals[2].append(p_val)\n",
    "\n",
    "                p_val = self.longest_runs(str_data)\n",
    "                pval_strings[3] += self.get_string(p_val)\n",
    "                pvals[3].append(p_val)\n",
    "\n",
    "                p_val = self.matrix_rank(str_data, matrix_size)\n",
    "                pval_strings[4] += self.get_string(p_val)\n",
    "                pvals[4].append(p_val)\n",
    "\n",
    "                p_val = self.spectral(str_data)\n",
    "                pval_strings[5] += self.get_string(p_val)\n",
    "                pvals[5].append(p_val)\n",
    "\n",
    "                p_val = self.non_overlapping_patterns(str_data, \"11110000\")\n",
    "                pval_strings[6] += self.get_string(p_val)\n",
    "                pvals[6].append(p_val)\n",
    "\n",
    "                p_val = self.overlapping_patterns(str_data, block_size=block_size)\n",
    "                pval_strings[7] += self.get_string(p_val)\n",
    "                pvals[7].append(p_val)\n",
    "\n",
    "                p_val = self.universal(str_data)\n",
    "                pval_strings[8] += self.get_string(p_val)\n",
    "                pvals[8].append(p_val)\n",
    "\n",
    "                p_val = self.linear_complexity(str_data, block_size=block_size)\n",
    "                pval_strings[9] += self.get_string(p_val)\n",
    "                pvals[9].append(p_val)\n",
    "\n",
    "                p_val_one, p_val_two = self.serial(str_data, method=\"both\")\n",
    "                # The serial test can return two p-values add one\n",
    "                pval_strings[10] += self.get_string(p_val_one)\n",
    "                pvals[10].append(p_val_one)\n",
    "                # The serial test can return two p-values add two\n",
    "                pval_strings[11] += self.get_string(p_val_two)\n",
    "                pvals[11].append(p_val_two)\n",
    "\n",
    "                p_val = self.approximate_entropy(str_data)\n",
    "                pval_strings[12] += self.get_string(p_val)\n",
    "                pvals[12].append(p_val)\n",
    "\n",
    "                p_val = self.cumulative_sums(str_data, method=\"forward\")\n",
    "                pval_strings[13] += self.get_string(p_val)\n",
    "                pvals[13].append(p_val)\n",
    "\n",
    "                p_val = self.cumulative_sums(str_data, method=\"backward\")\n",
    "                pval_strings[14] += self.get_string(p_val)\n",
    "                pvals[14].append(p_val)\n",
    "\n",
    "                p_values = self.random_excursions(str_data)\n",
    "                for j in range(15, 15 + 8):\n",
    "                    pvals[j].append(p_values[j - 15])\n",
    "                    pval_strings[j] += self.get_string(p_values[j - 15])\n",
    "\n",
    "                p_values = self.random_excursions_variant(str_data)\n",
    "                for j in range(23, 23 + 18):\n",
    "                    pvals[j].append(p_values[j - 23])\n",
    "                    pval_strings[j] += self.get_string(p_values[j - 23])\n",
    "\n",
    "            # For each sample calculate the aggregate p_value and aggregate pass %\n",
    "            aggregate_pvals, aggregate_pass = [], []\n",
    "            for i in range(len(binary_strings)):\n",
    "                for j in range(len(pvals)):\n",
    "                    aggregate_pvals.append(self.get_aggregate_pval(pvals[j]))\n",
    "                    aggregate_pass.append(self.get_aggregate_pass(pvals[j]))\n",
    "\n",
    "            tests_passed_this = 0\n",
    "            # Print the results to the console\n",
    "            self.print_dates(len(binary_strings))\n",
    "            for i in range(len(test_names)):\n",
    "                pass_string = Colours.Bold + Colours.Fail + \"FAIL!\\t\" + Colours.End\n",
    "                # NIST documentation recommends 0.96 ... but also more samples\n",
    "                if aggregate_pass[i] >= 0.90:\n",
    "                    pass_string = Colours.Bold + Colours.Pass + \"PASS!\\t\" + Colours.End\n",
    "                    tests_passed_this += 1\n",
    "                if (numpy.array(pvals[i]) == -1.0).sum() > 0:\n",
    "                    pass_string = Colours.Bold + \"SKIP!\\t\" + Colours.End\n",
    "\n",
    "                pval_string = Colours.Bold + Colours.Fail + \"p=\" + \"{0:.5f}\".format(\n",
    "                    aggregate_pvals[i]) + \"\\t\" + Colours.End\n",
    "                if aggregate_pvals[i] > self.confidence_level:\n",
    "                    pval_string = Colours.Bold + Colours.Pass + \"p=\" + \"{0:.5f}\".format(\n",
    "                        aggregate_pvals[i]) + \"\\t\" + Colours.End\n",
    "                if (numpy.array(pvals[i]) == -1.0).sum() > 0:\n",
    "                    pval_string = \"p=SKIPPED\\t\"\n",
    "\n",
    "                print(test_names[i] + pass_string + pval_string + pval_strings[i])\n",
    "\n",
    "            tests_passed.append(tests_passed_this)\n",
    "        return tests_passed\n",
    "\n",
    "    def load_test_data(self, data_set_name):\n",
    "        \"\"\"\n",
    "        This method is used to load in a test-data binary string. These data sets are included in the TestData directory\n",
    "        :param data_set_name: the name of the test data set to load e.g. e.csv, pi.csv, etc.\n",
    "        :return: a raw binary string of the data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            raw_data = \"\"\n",
    "            path = os.path.join(os.getcwd(), os.pardir, \"TestData\", data_set_name)\n",
    "            with open(path, 'r+') as data_set_file:\n",
    "                for line in data_set_file:\n",
    "                    raw_data += line.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\" \", \"\")\n",
    "            return raw_data\n",
    "        except FileNotFoundError:\n",
    "            path = os.path.join(os.getcwd(), os.pardir, \"TestData\", data_set_name)\n",
    "            print(\"File not found\", path, \"exiting\")\n",
    "            exit(0)\n",
    "\n",
    "    def generic_checker(self, test_name, expected, function, actual_out=None):\n",
    "        \"\"\"\n",
    "        This is a generic method for checking the outputs from one of the tests against known outputs to ensure that the\n",
    "        test if acting as expected. Essentially it is a unit tester.\n",
    "        :param test_name: the name of the test being checked\n",
    "        :param expected: a list of expected p-values\n",
    "        :param function: a reference to the function being checked\n",
    "        \"\"\"\n",
    "        # Compute the output using the function\n",
    "        print(\"\\n\\t\", Colours.Bold + test_name + Colours.End)\n",
    "        if \"Complexity\" in test_name or \"Matrix\" in test_name:\n",
    "            print(\"\\t\", \"This may take a while please be patient.\")\n",
    "        data_sets = [\"pi\", \"e\", \"sqrt2\", \"sqrt3\"]\n",
    "        if actual_out is None:\n",
    "            for i in range(len(data_sets)):\n",
    "                p_val = function(self.load_test_data(data_sets[i])[:1000000])\n",
    "                data_set_label = \"\".zfill(10 - len(data_sets[i])).replace(\"0\", \" \")\n",
    "                if abs(p_val - expected[i]) < self.epsilon:\n",
    "                    print(\"\\t\", Colours.Pass + data_sets[i], data_set_label, \"\\tp expected = \", expected[i],\n",
    "                          \"\\tp computed =\", \"{0:.6f}\".format(p_val) + Colours.End)\n",
    "                else:\n",
    "                    print(\"\\t\", Colours.Fail + data_sets[i], data_set_label, \"\\tp expected = \", expected[i],\n",
    "                          \"\\tp computed =\", \"{0:.6f}\".format(p_val) + Colours.End)\n",
    "        # Output has already been supplied\n",
    "        else:\n",
    "            i = 0\n",
    "            for p_val in actual_out:\n",
    "                data_set_label = \"\".zfill(10 - len(data_sets[i])).replace(\"0\", \" \")\n",
    "                if abs(p_val - expected[i]) < self.epsilon:\n",
    "                    print(\"\\t\", Colours.Pass + data_sets[i], data_set_label, \"\\tp expected = \", expected[i],\n",
    "                          \"\\tp computed =\", \"{0:.6f}\".format(p_val) + Colours.End)\n",
    "                else:\n",
    "                    print(\"\\t\", Colours.Fail + data_sets[i], data_set_label, \"\\tp expected = \", expected[i],\n",
    "                          \"\\tp computed =\", \"{0:.6f}\".format(p_val) + Colours.End)\n",
    "                i += 1\n",
    "\n",
    "    def test_randomness_tester(self):\n",
    "        \"\"\"\n",
    "        This method calls the method calls each one of the checks of the randomness tests contained in this class\n",
    "        \"\"\"\n",
    "        self.monobit_check()\n",
    "        self.block_frequency_check()\n",
    "        self.independent_runs_check()\n",
    "        self.longest_runs_check()\n",
    "        self.spectral_check()\n",
    "        self.non_overlapping_patterns_check()\n",
    "        self.overlapping_patterns_check()\n",
    "        self.universal_check()\n",
    "        self.serial_check()\n",
    "        self.approximate_entropy_check()\n",
    "        self.cumulative_sums_check()\n",
    "        self.random_excursions_check()\n",
    "        self.random_excursions_variant_check()\n",
    "        # These checks are slow\n",
    "        self.matrix_rank_check()\n",
    "        self.linear_complexity_check()\n",
    "\n",
    "    def count_zeros_and_ones(self, bin_data: str):\n",
    "        \"\"\"\n",
    "        This is just a simple method for counting zeros and ones\n",
    "        :param bin_data: the data from which to count zeros and ones\n",
    "        :return: nothing.\n",
    "        \"\"\"\n",
    "        ones, zeros = 0, 0\n",
    "        # If the char is 0 minus 1, else add 1\n",
    "        for char in bin_data:\n",
    "            if char == '0':\n",
    "                zeros += 1\n",
    "            else:\n",
    "                ones += 1\n",
    "        print(\"\\t\", Colours.Italics + \"Count 1 =\", ones, \"Count 0 =\", zeros, Colours.End)\n",
    "\n",
    "    def monobit(self, bin_data: str):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the proportion of zeros and ones for the entire sequence. The purpose of this test is\n",
    "        to determine whether the number of ones and zeros in a sequence are approximately the same as would be expected\n",
    "        for a truly random sequence. This test assesses the closeness of the fraction of ones to 1/2, that is the number\n",
    "        of ones and zeros ina  sequence should be about the same. All subsequent tests depend on this test.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        # If the char is 0 minus 1, else add 1\n",
    "        for char in bin_data:\n",
    "            if char == '0':\n",
    "                count -= 1\n",
    "            else:\n",
    "                count += 1\n",
    "        # Calculate the p value\n",
    "        sobs = count / math.sqrt(len(bin_data))\n",
    "        p_val = spc.erfc(math.fabs(sobs) / math.sqrt(2))\n",
    "        return p_val\n",
    "\n",
    "    def monobit_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the monobit test method based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.578211, 0.953749, 0.811881, 0.610051]\n",
    "        self.generic_checker(\"Testing Monobit Test\", expected, self.monobit)\n",
    "\n",
    "    def block_frequency(self, bin_data: str, block_size=128):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this tests is the proportion of ones within M-bit blocks. The purpose of this tests is to determine\n",
    "        whether the frequency of ones in an M-bit block is approximately M/2, as would be expected under an assumption\n",
    "        of randomness. For block size M=1, this test degenerates to the monobit frequency test.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        :param block_size: the size of the blocks that the binary sequence is partitioned into\n",
    "        \"\"\"\n",
    "        # Work out the number of blocks, discard the remainder\n",
    "        num_blocks = math.floor(len(bin_data) / block_size)\n",
    "        block_start, block_end = 0, block_size\n",
    "        # Keep track of the proportion of ones per block\n",
    "        proportion_sum = 0.0\n",
    "        for i in range(num_blocks):\n",
    "            # Slice the binary string into a block\n",
    "            block_data = bin_data[block_start:block_end]\n",
    "            # Keep track of the number of ones\n",
    "            ones_count = 0\n",
    "            for char in block_data:\n",
    "                if char == '1':\n",
    "                    ones_count += 1\n",
    "            pi = ones_count / block_size\n",
    "            proportion_sum += pow(pi - 0.5, 2.0)\n",
    "            # Update the slice locations\n",
    "            block_start += block_size\n",
    "            block_end += block_size\n",
    "        # Calculate the p-value\n",
    "        chi_squared = 4.0 * block_size * proportion_sum\n",
    "        p_val = spc.gammaincc(num_blocks / 2, chi_squared / 2)\n",
    "        return p_val\n",
    "\n",
    "    def block_frequency_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the block frequency test method based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.380615, 0.211072, 0.833222, 0.473961]\n",
    "        self.generic_checker(\"Testing Block Frequency Test\", expected, self.block_frequency)\n",
    "\n",
    "    def independent_runs(self, bin_data: str):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this tests if the total number of runs in the sequences, where a run is an uninterrupted sequence\n",
    "        of identical bits. A run of length k consists of k identical bits and is bounded before and after with a bit of\n",
    "        the opposite value. The purpose of the runs tests is to determine whether the number of runs of ones and zeros\n",
    "        of various lengths is as expected for a random sequence. In particular, this tests determines whether the\n",
    "        oscillation between zeros and ones is either too fast or too slow.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        ones_count, n = 0, len(bin_data)\n",
    "        for char in bin_data:\n",
    "            if char == '1':\n",
    "                ones_count += 1\n",
    "        p, vobs = float(ones_count / n), 1\n",
    "        tau = 2 / math.sqrt(len(bin_data))\n",
    "        if abs(p - 0.5) > tau:\n",
    "            return 0.0\n",
    "        else:\n",
    "            for i in range(1, n):\n",
    "                if bin_data[i] != bin_data[i - 1]:\n",
    "                    vobs += 1\n",
    "            # expected_runs = 1 + 2 * (n - 1) * 0.5 * 0.5\n",
    "            # print(\"\\t\", Colours.Italics + \"Observed runs =\", vobs, \"Expected runs\", expected_runs, Colours.End)\n",
    "            num = abs(vobs - 2.0 * n * p * (1.0 - p))\n",
    "            den = 2.0 * math.sqrt(2.0 * n) * p * (1.0 - p)\n",
    "            p_val = spc.erfc(float(num / den))\n",
    "            return p_val\n",
    "\n",
    "    def independent_runs_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the runs test method based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.419268, 0.561917, 0.313427, 0.261123]\n",
    "        self.generic_checker(\"Testing Independent Runs Test\", expected, self.independent_runs)\n",
    "\n",
    "    def longest_runs(self, bin_data: str):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of the tests is the longest run of ones within M-bit blocks. The purpose of this tests is to determine\n",
    "        whether the length of the longest run of ones within the tested sequences is consistent with the length of the\n",
    "        longest run of ones that would be expected in a random sequence. Note that an irregularity in the expected\n",
    "        length of the longest run of ones implies that there is also an irregularity ub tge expected length of the long\n",
    "        est run of zeroes. Therefore, only one test is necessary for this statistical tests of randomness\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        if len(bin_data) < 128:\n",
    "            print(\"\\t\", \"Not enough data to run test!\")\n",
    "            return -1.0\n",
    "        elif len(bin_data) < 6272:\n",
    "            k, m = 3, 8\n",
    "            v_values = [1, 2, 3, 4]\n",
    "            pik_values = [0.21484375, 0.3671875, 0.23046875, 0.1875]\n",
    "        elif len(bin_data) < 75000:\n",
    "            k, m = 5, 128\n",
    "            v_values = [4, 5, 6, 7, 8, 9]\n",
    "            pik_values = [0.1174035788, 0.242955959, 0.249363483, 0.17517706, 0.102701071, 0.112398847]\n",
    "        else:\n",
    "            k, m = 6, 10000\n",
    "            v_values = [10, 11, 12, 13, 14, 15, 16]\n",
    "            pik_values = [0.0882, 0.2092, 0.2483, 0.1933, 0.1208, 0.0675, 0.0727]\n",
    "\n",
    "        # Work out the number of blocks, discard the remainder\n",
    "        # pik = [0.2148, 0.3672, 0.2305, 0.1875]\n",
    "        num_blocks = math.floor(len(bin_data) / m)\n",
    "        frequencies = numpy.zeros(k + 1)\n",
    "        block_start, block_end = 0, m\n",
    "        for i in range(num_blocks):\n",
    "            # Slice the binary string into a block\n",
    "            block_data = bin_data[block_start:block_end]\n",
    "            # Keep track of the number of ones\n",
    "            max_run_count, run_count = 0, 0\n",
    "            for j in range(0, m):\n",
    "                if block_data[j] == '1':\n",
    "                    run_count += 1\n",
    "                    max_run_count = max(max_run_count, run_count)\n",
    "                else:\n",
    "                    max_run_count = max(max_run_count, run_count)\n",
    "                    run_count = 0\n",
    "            max_run_count = max(max_run_count, run_count)\n",
    "            if max_run_count < v_values[0]:\n",
    "                frequencies[0] += 1\n",
    "            for j in range(k):\n",
    "                if max_run_count == v_values[j]:\n",
    "                    frequencies[j] += 1\n",
    "            if max_run_count > v_values[k - 1]:\n",
    "                frequencies[k] += 1\n",
    "            block_start += m\n",
    "            block_end += m\n",
    "        # print(frequencies)\n",
    "        chi_squared = 0\n",
    "        for i in range(len(frequencies)):\n",
    "            chi_squared += (pow(frequencies[i] - (num_blocks * pik_values[i]), 2.0)) / (num_blocks * pik_values[i])\n",
    "        p_val = spc.gammaincc(float(k / 2), float(chi_squared / 2))\n",
    "        return p_val\n",
    "\n",
    "    def longest_runs_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the longest run test method based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.024390, 0.718945, 0.012117, 0.446726]\n",
    "        self.generic_checker(\"Testing Longest Runs Test\", expected, self.longest_runs)\n",
    "\n",
    "    def matrix_rank(self, bin_data: str, matrix_size=32):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of the test is the rank of disjoint sub-matrices of the entire sequence. The purpose of this test is\n",
    "        to check for linear dependence among fixed length sub strings of the original sequence. Note that this test\n",
    "        also appears in the DIEHARD battery of tests.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        shape = (matrix_size, matrix_size)\n",
    "        n = len(bin_data)\n",
    "        block_size = int(matrix_size * matrix_size)\n",
    "        num_m = math.floor(n / (matrix_size * matrix_size))\n",
    "        block_start, block_end = 0, block_size\n",
    "        # print(q, n, num_m, block_size)\n",
    "\n",
    "        if num_m > 0:\n",
    "            max_ranks = [0, 0, 0]\n",
    "            for im in range(num_m):\n",
    "                block_data = bin_data[block_start:block_end]\n",
    "                block = numpy.zeros(len(block_data))\n",
    "                for i in range(len(block_data)):\n",
    "                    if block_data[i] == '1':\n",
    "                        block[i] = 1.0\n",
    "                m = block.reshape(shape)\n",
    "                ranker = BinaryMatrix(m, matrix_size, matrix_size)\n",
    "                rank = ranker.compute_rank()\n",
    "                # print(rank)\n",
    "                if rank == matrix_size:\n",
    "                    max_ranks[0] += 1\n",
    "                elif rank == (matrix_size - 1):\n",
    "                    max_ranks[1] += 1\n",
    "                else:\n",
    "                    max_ranks[2] += 1\n",
    "                # Update index trackers\n",
    "                block_start += block_size\n",
    "                block_end += block_size\n",
    "\n",
    "            piks = [1.0, 0.0, 0.0]\n",
    "            for x in range(1, 50):\n",
    "                piks[0] *= 1 - (1.0 / (2 ** x))\n",
    "            piks[1] = 2 * piks[0]\n",
    "            piks[2] = 1 - piks[0] - piks[1]\n",
    "\n",
    "            chi = 0.0\n",
    "            for i in range(len(piks)):\n",
    "                chi += pow((max_ranks[i] - piks[i] * num_m), 2.0) / (piks[i] * num_m)\n",
    "            p_val = math.exp(-chi / 2)\n",
    "            return p_val\n",
    "        else:\n",
    "            return -1.0\n",
    "\n",
    "    def matrix_rank_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the binary matrix rank test based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.083553, 0.306156, 0.823810, 0.314498]\n",
    "        self.generic_checker(\"Testing Matrix Rank Test\", expected, self.matrix_rank)\n",
    "\n",
    "    def spectral(self, bin_data: str):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the peak heights in the Discrete Fourier Transform of the sequence. The purpose of\n",
    "        this test is to detect periodic features (i.e., repetitive patterns that are near each other) in the tested\n",
    "        sequence that would indicate a deviation from the assumption of randomness. The intention is to detect whether\n",
    "        the number of peaks exceeding the 95 % threshold is significantly different than 5 %.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        n = len(bin_data)\n",
    "        plus_minus_one = []\n",
    "        for char in bin_data:\n",
    "            if char == '0':\n",
    "                plus_minus_one.append(-1)\n",
    "            elif char == '1':\n",
    "                plus_minus_one.append(1)\n",
    "        # Product discrete fourier transform of plus minus one\n",
    "        s = sff.fft(plus_minus_one)\n",
    "        modulus = numpy.abs(s[0:n / 2])\n",
    "        tau = numpy.sqrt(numpy.log(1 / 0.05) * n)\n",
    "        # Theoretical number of peaks\n",
    "        count_n0 = 0.95 * (n / 2)\n",
    "        # Count the number of actual peaks m > T\n",
    "        count_n1 = len(numpy.where(modulus < tau)[0])\n",
    "        # Calculate d and return the p value statistic\n",
    "        d = (count_n1 - count_n0) / numpy.sqrt(n * 0.95 * 0.05 / 4)\n",
    "        p_val = spc.erfc(abs(d) / numpy.sqrt(2))\n",
    "        return p_val\n",
    "\n",
    "    def spectral_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the spectral test based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.010186, 0.847187, 0.581909, 0.776046]\n",
    "        self.generic_checker(\"Check Spectral Test\", expected, self.spectral)\n",
    "\n",
    "    def non_overlapping_patterns(self, bin_data: str, pattern=\"000000001\", num_blocks=8):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the number of occurrences of pre-specified target strings. The purpose of this\n",
    "        test is to detect generators that produce too many occurrences of a given non-periodic (aperiodic) pattern.\n",
    "        For this test and for the Overlapping Template Matching test of Section 2.8, an m-bit window is used to\n",
    "        search for a specific m-bit pattern. If the pattern is not found, the window slides one bit position. If the\n",
    "        pattern is found, the window is reset to the bit after the found pattern, and the search resumes.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :param pattern: the pattern to match to\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        n = len(bin_data)\n",
    "        pattern_size = len(pattern)\n",
    "        block_size = math.floor(n / num_blocks)\n",
    "        pattern_counts = numpy.zeros(num_blocks)\n",
    "        # For each block in the data\n",
    "        for i in range(num_blocks):\n",
    "            block_start = i * block_size\n",
    "            block_end = block_start + block_size\n",
    "            block_data = bin_data[block_start:block_end]\n",
    "            # Count the number of pattern hits\n",
    "            j = 0\n",
    "            while j < block_size:\n",
    "                sub_block = block_data[j:j + pattern_size]\n",
    "                if sub_block == pattern:\n",
    "                    pattern_counts[i] += 1\n",
    "                    j += pattern_size\n",
    "                else:\n",
    "                    j += 1\n",
    "        # Calculate the theoretical mean and variance\n",
    "        mean = (block_size - pattern_size + 1) / pow(2, pattern_size)\n",
    "        var = block_size * ((1 / pow(2, pattern_size)) - (((2 * pattern_size) - 1) / (pow(2, pattern_size * 2))))\n",
    "        # Calculate the Chi Squared statistic for these pattern matches\n",
    "        chi_squared = 0\n",
    "        for i in range(num_blocks):\n",
    "            chi_squared += pow(pattern_counts[i] - mean, 2.0) / var\n",
    "        # Calculate and return the p value statistic\n",
    "        p_val = spc.gammaincc(num_blocks / 2, chi_squared / 2)\n",
    "        return p_val\n",
    "\n",
    "    def non_overlapping_patterns_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the non overlapping patterns test based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.165757, 0.078790, 0.569461, 0.532235]\n",
    "        self.generic_checker(\"Check Non Overlapping Patterns Test\", expected, self.non_overlapping_patterns)\n",
    "\n",
    "    def overlapping_patterns(self, bin_data: str, pattern_size=9, block_size=1032):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of the Overlapping Template Matching test is the number of occurrences of pre-specified target\n",
    "        strings. Both this test and the Non-overlapping Template Matching test of Section 2.7 use an m-bit\n",
    "        window to search for a specific m-bit pattern. As with the test in Section 2.7, if the pattern is not found,\n",
    "        the window slides one bit position. The difference between this test and the test in Section 2.7 is that\n",
    "        when the pattern is found, the window slides only one bit before resuming the search.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :param pattern_size: the length of the pattern\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        n = len(bin_data)\n",
    "        pattern = \"\"\n",
    "        for i in range(pattern_size):\n",
    "            pattern += \"1\"\n",
    "        num_blocks = math.floor(n / block_size)\n",
    "        lambda_val = float(block_size - pattern_size + 1) / pow(2, pattern_size)\n",
    "        eta = lambda_val / 2.0\n",
    "\n",
    "        piks = [self.get_prob(i, eta) for i in range(5)]\n",
    "        diff = float(numpy.array(piks).sum())\n",
    "        piks.append(1.0 - diff)\n",
    "\n",
    "        pattern_counts = numpy.zeros(6)\n",
    "        for i in range(num_blocks):\n",
    "            block_start = i * block_size\n",
    "            block_end = block_start + block_size\n",
    "            block_data = bin_data[block_start:block_end]\n",
    "            # Count the number of pattern hits\n",
    "            pattern_count = 0\n",
    "            j = 0\n",
    "            while j < block_size:\n",
    "                sub_block = block_data[j:j + pattern_size]\n",
    "                if sub_block == pattern:\n",
    "                    pattern_count += 1\n",
    "                j += 1\n",
    "            if pattern_count <= 4:\n",
    "                pattern_counts[pattern_count] += 1\n",
    "            else:\n",
    "                pattern_counts[5] += 1\n",
    "\n",
    "        chi_squared = 0.0\n",
    "        for i in range(len(pattern_counts)):\n",
    "            chi_squared += pow(pattern_counts[i] - num_blocks * piks[i], 2.0) / (num_blocks * piks[i])\n",
    "        return spc.gammaincc(5.0 / 2.0, chi_squared / 2.0)\n",
    "\n",
    "    def get_prob(self, u, x):\n",
    "        out = 1.0 * numpy.exp(-x)\n",
    "        if u != 0:\n",
    "            out = 1.0 * x * numpy.exp(2 * -x) * (2 ** -u) * spc.hyp1f1(u + 1, 2, x)\n",
    "        return out\n",
    "\n",
    "    def overlapping_patterns_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the non overlapping patterns test based on the example in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.296897, 0.110434, 0.791982, 0.082716]\n",
    "        self.generic_checker(\"Check Overlapping Patterns Test\", expected, self.overlapping_patterns)\n",
    "\n",
    "    def universal(self, bin_data: str):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the number of bits between matching patterns (a measure that is related to the\n",
    "        length of a compressed sequence). The purpose of the test is to detect whether or not the sequence can be\n",
    "        significantly compressed without loss of information. A significantly compressible sequence is considered\n",
    "        to be non-random. **This test is always skipped because the requirements on the lengths of the binary\n",
    "        strings are too high i.e. there have not been enough trading days to meet the requirements.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the p-value from the test\n",
    "        \"\"\"\n",
    "        # The below table is less relevant for us traders and markets than it is for security people\n",
    "        n = len(bin_data)\n",
    "        pattern_size = 5\n",
    "        if n >= 387840:\n",
    "            pattern_size = 6\n",
    "        if n >= 904960:\n",
    "            pattern_size = 7\n",
    "        if n >= 2068480:\n",
    "            pattern_size = 8\n",
    "        if n >= 4654080:\n",
    "            pattern_size = 9\n",
    "        if n >= 10342400:\n",
    "            pattern_size = 10\n",
    "        if n >= 22753280:\n",
    "            pattern_size = 11\n",
    "        if n >= 49643520:\n",
    "            pattern_size = 12\n",
    "        if n >= 107560960:\n",
    "            pattern_size = 13\n",
    "        if n >= 231669760:\n",
    "            pattern_size = 14\n",
    "        if n >= 496435200:\n",
    "            pattern_size = 15\n",
    "        if n >= 1059061760:\n",
    "            pattern_size = 16\n",
    "\n",
    "        if 5 < pattern_size < 16:\n",
    "            # Create the biggest binary string of length pattern_size\n",
    "            ones = \"\"\n",
    "            for i in range(pattern_size):\n",
    "                ones += \"1\"\n",
    "\n",
    "            # How long the state list should be\n",
    "            num_ints = int(ones, 2)\n",
    "            vobs = numpy.zeros(num_ints + 1)\n",
    "\n",
    "            # Keeps track of the blocks, and whether were are initializing or summing\n",
    "            num_blocks = math.floor(n / pattern_size)\n",
    "            init_bits = 10 * pow(2, pattern_size)\n",
    "            test_bits = num_blocks - init_bits\n",
    "\n",
    "            # These are the expected values assuming randomness (uniform)\n",
    "            c = 0.7 - 0.8 / pattern_size + (4 + 32 / pattern_size) * pow(test_bits, -3 / pattern_size) / 15\n",
    "            variance = [0, 0, 0, 0, 0, 0, 2.954, 3.125, 3.238, 3.311, 3.356, 3.384, 3.401, 3.410, 3.416, 3.419, 3.421]\n",
    "            expected = [0, 0, 0, 0, 0, 0, 5.2177052, 6.1962507, 7.1836656, 8.1764248, 9.1723243,\n",
    "                        10.170032, 11.168765, 12.168070, 13.167693, 14.167488, 15.167379]\n",
    "            sigma = c * math.sqrt(variance[pattern_size] / test_bits)\n",
    "\n",
    "            cumsum = 0.0\n",
    "            for i in range(num_blocks):\n",
    "                block_start = i * pattern_size\n",
    "                block_end = block_start + pattern_size\n",
    "                block_data = bin_data[block_start: block_end]\n",
    "                # Work out what state we are in\n",
    "                int_rep = int(block_data, 2)\n",
    "\n",
    "                # Initialize the state list\n",
    "                if i < init_bits:\n",
    "                    vobs[int_rep] = i + 1\n",
    "                else:\n",
    "                    initial = vobs[int_rep]\n",
    "                    vobs[int_rep] = i + 1\n",
    "                    cumsum += math.log(i - initial + 1, 2)\n",
    "\n",
    "            # Calculate the statistic\n",
    "            phi = float(cumsum / test_bits)\n",
    "            stat = abs(phi - expected[pattern_size]) / (float(math.sqrt(2)) * sigma)\n",
    "            p_val = spc.erfc(stat)\n",
    "            return p_val\n",
    "        else:\n",
    "            return -1.0\n",
    "\n",
    "    def universal_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the universal test based on the examples in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.669012, 0.282568, 0.130805, 0.165981]\n",
    "        self.generic_checker(\"Check Universal Test\", expected, self.universal)\n",
    "\n",
    "    def linear_complexity(self, bin_data: str, block_size=500):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the length of a linear feedback shift register (LFSR). The purpose of this test is to\n",
    "        determine whether or not the sequence is complex enough to be considered random. Random sequences are\n",
    "        characterized by longer LFSRs. An LFSR that is too short implies non-randomness.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :param block_size: the size of the blocks to divide bin_data into. Recommended block_size >= 500\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        dof = 6\n",
    "        piks = [0.01047, 0.03125, 0.125, 0.5, 0.25, 0.0625, 0.020833]\n",
    "\n",
    "        t2 = (block_size / 3.0 + 2.0 / 9) / 2 ** block_size\n",
    "        mean = 0.5 * block_size + (1.0 / 36) * (9 + (-1) ** (block_size + 1)) - t2\n",
    "\n",
    "        num_blocks = int(len(bin_data) / block_size)\n",
    "        if num_blocks > 1:\n",
    "            block_end = block_size\n",
    "            block_start = 0\n",
    "            blocks = []\n",
    "            for i in range(num_blocks):\n",
    "                blocks.append(bin_data[block_start:block_end])\n",
    "                block_start += block_size\n",
    "                block_end += block_size\n",
    "\n",
    "            complexities = []\n",
    "            for block in blocks:\n",
    "                complexities.append(self.berlekamp_massey_algorithm(block))\n",
    "\n",
    "            t = ([-1.0 * (((-1) ** block_size) * (chunk - mean) + 2.0 / 9) for chunk in complexities])\n",
    "            vg = numpy.histogram(t, bins=[-9999999999, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 9999999999])[0][::-1]\n",
    "            im = ([((vg[ii] - num_blocks * piks[ii]) ** 2) / (num_blocks * piks[ii]) for ii in range(7)])\n",
    "\n",
    "            chi_squared = 0.0\n",
    "            for i in range(len(piks)):\n",
    "                chi_squared += im[i]\n",
    "            p_val = spc.gammaincc(dof / 2.0, chi_squared / 2.0)\n",
    "            return p_val\n",
    "        else:\n",
    "            return -1.0\n",
    "\n",
    "    def berlekamp_massey_algorithm(self, block_data: str):\n",
    "        \"\"\"\n",
    "        An implementation of the Berlekamp Massey Algorithm. Taken from Wikipedia [1]\n",
    "        [1] - https://en.wikipedia.org/wiki/Berlekamp-Massey_algorithm\n",
    "\n",
    "        The BerlekampMassey algorithm is an algorithm that will find the shortest linear feedback shift register (LFSR)\n",
    "        for a given binary output sequence. The algorithm will also find the minimal polynomial of a linearly recurrent\n",
    "        sequence in an arbitrary field. The field requirement means that the BerlekampMassey algorithm requires all\n",
    "        non-zero elements to have a multiplicative inverse.\n",
    "\n",
    "        :param block_data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        n = len(block_data)\n",
    "        c = numpy.zeros(n)\n",
    "        b = numpy.zeros(n)\n",
    "        c[0], b[0] = 1, 1\n",
    "        l, m, i = 0, -1, 0\n",
    "        int_data = [int(el) for el in block_data]\n",
    "        while i < n:\n",
    "            v = int_data[(i - l):i]\n",
    "            v = v[::-1]\n",
    "            cc = c[1:l + 1]\n",
    "            d = (int_data[i] + numpy.dot(v, cc)) % 2\n",
    "            if d == 1:\n",
    "                temp = copy.copy(c)\n",
    "                p = numpy.zeros(n)\n",
    "                for j in range(0, l):\n",
    "                    if b[j] == 1:\n",
    "                        p[j + i - m] = 1\n",
    "                c = (c + p) % 2\n",
    "                if l <= 0.5 * i:\n",
    "                    l = i + 1 - l\n",
    "                    m = i\n",
    "                    b = temp\n",
    "            i += 1\n",
    "        return l\n",
    "\n",
    "    def linear_complexity_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the linear complexity test based on the examples in the NIST documentation\n",
    "        \"\"\"\n",
    "        expected = [0.255475, 0.826335, 0.317127, 0.346469]\n",
    "        self.generic_checker(\"Check Linear Complexity Test\", expected, self.linear_complexity)\n",
    "\n",
    "    def serial(self, bin_data: str, pattern_length=16, method=\"first\"):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the frequency of all possible overlapping m-bit patterns across the entire\n",
    "        sequence. The purpose of this test is to determine whether the number of occurrences of the 2m m-bit\n",
    "        overlapping patterns is approximately the same as would be expected for a random sequence. Random\n",
    "        sequences have uniformity; that is, every m-bit pattern has the same chance of appearing as every other\n",
    "        m-bit pattern. Note that for m = 1, the Serial test is equivalent to the Frequency test of Section 2.1.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :param pattern_length: the length of the pattern (m)\n",
    "        :return: the P value\n",
    "        \"\"\"\n",
    "        n = len(bin_data)\n",
    "        # Add first m-1 bits to the end\n",
    "        bin_data += bin_data[:pattern_length - 1:]\n",
    "\n",
    "        # Get max length one patterns for m, m-1, m-2\n",
    "        max_pattern = ''\n",
    "        for i in range(pattern_length + 1):\n",
    "            max_pattern += '1'\n",
    "\n",
    "        # Keep track of each pattern's frequency (how often it appears)\n",
    "        vobs_one = numpy.zeros(int(max_pattern[0:pattern_length:], 2) + 1)\n",
    "        vobs_two = numpy.zeros(int(max_pattern[0:pattern_length - 1:], 2) + 1)\n",
    "        vobs_thr = numpy.zeros(int(max_pattern[0:pattern_length - 2:], 2) + 1)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Work out what pattern is observed\n",
    "            vobs_one[int(bin_data[i:i + pattern_length:], 2)] += 1\n",
    "            vobs_two[int(bin_data[i:i + pattern_length - 1:], 2)] += 1\n",
    "            vobs_thr[int(bin_data[i:i + pattern_length - 2:], 2)] += 1\n",
    "\n",
    "        vobs = [vobs_one, vobs_two, vobs_thr]\n",
    "        sums = numpy.zeros(3)\n",
    "        for i in range(3):\n",
    "            for j in range(len(vobs[i])):\n",
    "                sums[i] += pow(vobs[i][j], 2)\n",
    "            sums[i] = (sums[i] * pow(2, pattern_length - i) / n) - n\n",
    "\n",
    "        # Calculate the test statistics and p values\n",
    "        del1 = sums[0] - sums[1]\n",
    "        del2 = sums[0] - 2.0 * sums[1] + sums[2]\n",
    "        p_val_one = spc.gammaincc(pow(2, pattern_length - 1) / 2, del1 / 2.0)\n",
    "        p_val_two = spc.gammaincc(pow(2, pattern_length - 2) / 2, del2 / 2.0)\n",
    "\n",
    "        # For checking the outputs\n",
    "        if method == \"first\":\n",
    "            return p_val_one\n",
    "        elif method == \"both\":\n",
    "            return p_val_one, p_val_two\n",
    "        else:\n",
    "            # I am not sure if this is correct, but it makes sense to me.\n",
    "            return min(p_val_one, p_val_two)\n",
    "\n",
    "    def serial_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the serial test based on the examples in the NIST documentation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        expected = [0.143005, 0.766182, 0.861925, 0.157500]\n",
    "        self.generic_checker(\"Check Serial Test\", expected, self.serial)\n",
    "\n",
    "    def approximate_entropy(self, bin_data: str, pattern_length=10):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        As with the Serial test of Section 2.11, the focus of this test is the frequency of all possible overlapping\n",
    "        m-bit patterns across the entire sequence. The purpose of the test is to compare the frequency of overlapping\n",
    "        blocks of two consecutive/adjacent lengths (m and m+1) against the expected result for a random sequence.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :param pattern_length: the length of the pattern (m)\n",
    "        :return: the P value\n",
    "        \"\"\"\n",
    "        n = len(bin_data)\n",
    "        # Add first m+1 bits to the end\n",
    "        # NOTE: documentation says m-1 bits but that doesnt make sense, or work.\n",
    "        bin_data += bin_data[:pattern_length + 1:]\n",
    "\n",
    "        # Get max length one patterns for m, m-1, m-2\n",
    "        max_pattern = ''\n",
    "        for i in range(pattern_length + 2):\n",
    "            max_pattern += '1'\n",
    "\n",
    "        # Keep track of each pattern's frequency (how often it appears)\n",
    "        vobs_one = numpy.zeros(int(max_pattern[0:pattern_length:], 2) + 1)\n",
    "        vobs_two = numpy.zeros(int(max_pattern[0:pattern_length + 1:], 2) + 1)\n",
    "\n",
    "        for i in range(n):\n",
    "            # Work out what pattern is observed\n",
    "            vobs_one[int(bin_data[i:i + pattern_length:], 2)] += 1\n",
    "            vobs_two[int(bin_data[i:i + pattern_length + 1:], 2)] += 1\n",
    "\n",
    "        # Calculate the test statistics and p values\n",
    "        vobs = [vobs_one, vobs_two]\n",
    "        sums = numpy.zeros(2)\n",
    "        for i in range(2):\n",
    "            for j in range(len(vobs[i])):\n",
    "                if vobs[i][j] > 0:\n",
    "                    sums[i] += vobs[i][j] * math.log(vobs[i][j] / n)\n",
    "        sums /= n\n",
    "        ape = sums[0] - sums[1]\n",
    "        chi_squared = 2.0 * n * (math.log(2) - ape)\n",
    "        p_val = spc.gammaincc(pow(2, pattern_length - 1), chi_squared / 2.0)\n",
    "        return p_val\n",
    "\n",
    "    def approximate_entropy_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the serial test based on the examples in the NIST documentation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        expected = [0.361595, 0.700073, 0.884740, 0.180481]\n",
    "        self.generic_checker(\"Check Approximate Entropy Test\", expected, self.approximate_entropy)\n",
    "\n",
    "    def cumulative_sums(self, bin_data: str, method=\"forward\"):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the maximal excursion (from zero) of the random walk defined by the cumulative sum of\n",
    "        adjusted (-1, +1) digits in the sequence. The purpose of the test is to determine whether the cumulative sum of\n",
    "        the partial sequences occurring in the tested sequence is too large or too small relative to the expected\n",
    "        behavior of that cumulative sum for random sequences. This cumulative sum may be considered as a random walk.\n",
    "        For a random sequence, the excursions of the random walk should be near zero. For certain types of non-random\n",
    "        sequences, the excursions of this random walk from zero will be large.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :param method: the method used to calculate the statistic\n",
    "        :return: the P-value\n",
    "        \"\"\"\n",
    "        n = len(bin_data)\n",
    "        counts = numpy.zeros(n)\n",
    "        # Calculate the statistic using a walk forward\n",
    "        if method != \"forward\":\n",
    "            bin_data = bin_data[::-1]\n",
    "\n",
    "        ix = 0\n",
    "        for char in bin_data:\n",
    "            sub = 1\n",
    "            if char == '0':\n",
    "                sub = -1\n",
    "            if ix > 0:\n",
    "                counts[ix] = counts[ix - 1] + sub\n",
    "            else:\n",
    "                counts[ix] = sub\n",
    "            ix += 1\n",
    "\n",
    "        # This is the maximum absolute level obtained by the sequence\n",
    "        abs_max = numpy.max(numpy.abs(counts))\n",
    "\n",
    "        start = int(numpy.floor(0.25 * numpy.floor(-n / abs_max) + 1))\n",
    "        end = int(numpy.floor(0.25 * numpy.floor(n / abs_max) - 1))\n",
    "        terms_one = []\n",
    "        for k in range(start, end + 1):\n",
    "            sub = sst.norm.cdf((4 * k - 1) * abs_max / numpy.sqrt(n))\n",
    "            terms_one.append(sst.norm.cdf((4 * k + 1) * abs_max / numpy.sqrt(n)) - sub)\n",
    "\n",
    "        start = int(numpy.floor(0.25 * numpy.floor(-n / abs_max - 3)))\n",
    "        end = int(numpy.floor(0.25 * numpy.floor(n / abs_max) - 1))\n",
    "        terms_two = []\n",
    "        for k in range(start, end + 1):\n",
    "            sub = sst.norm.cdf((4 * k + 1) * abs_max / numpy.sqrt(n))\n",
    "            terms_two.append(sst.norm.cdf((4 * k + 3) * abs_max / numpy.sqrt(n)) - sub)\n",
    "\n",
    "        p_val = 1.0 - numpy.sum(numpy.array(terms_one))\n",
    "        p_val += numpy.sum(numpy.array(terms_two))\n",
    "        return p_val\n",
    "\n",
    "    def cumulative_sums_check(self):\n",
    "        \"\"\"\n",
    "        This is a test method for the serial test based on the examples in the NIST documentation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Assumes forward method used\n",
    "        expected = [0.628308, 0.669887, 0.879009, 0.917121]\n",
    "        self.generic_checker(\"Check Cumulative Sums Test\", expected, self.cumulative_sums)\n",
    "        # For backward method uncomment these and change default method\n",
    "        # expected = [0.663369, 0.724266, 0.957206, 0.689519]\n",
    "        # self.generic_checker(\"Check Cumulative Sums Test\", expected, self.cumulative_sums)\n",
    "\n",
    "    def random_excursions(self, bin_data):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the number of cycles having exactly K visits in a cumulative sum random walk. The\n",
    "        cumulative sum random walk is derived from partial sums after the (0,1) sequence is transferred to the\n",
    "        appropriate (-1, +1) sequence. A cycle of a random walk consists of a sequence of steps of unit length taken at\n",
    "        random that begin at and return to the origin. The purpose of this test is to determine if the number of visits\n",
    "        to a particular state within a cycle deviates from what one would expect for a random sequence. This test is\n",
    "        actually a series of eight tests (and conclusions), one test and conclusion for each of the states:\n",
    "\n",
    "        States -> -4, -3, -2, -1 and +1, +2, +3, +4.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the P-value\n",
    "        \"\"\"\n",
    "        # Turn all the binary digits into +1 or -1\n",
    "        int_data = numpy.zeros(len(bin_data))\n",
    "        for i in range(len(bin_data)):\n",
    "            if bin_data[i] == '0':\n",
    "                int_data[i] = -1.0\n",
    "            else:\n",
    "                int_data[i] = 1.0\n",
    "\n",
    "        # Calculate the cumulative sum\n",
    "        cumulative_sum = numpy.cumsum(int_data)\n",
    "        # Append a 0 to the end and beginning of the sum\n",
    "        cumulative_sum = numpy.append(cumulative_sum, [0])\n",
    "        cumulative_sum = numpy.append([0], cumulative_sum)\n",
    "\n",
    "        # These are the states we are going to look at\n",
    "        x_values = numpy.array([-4, -3, -2, -1, 1, 2, 3, 4])\n",
    "\n",
    "        # Identify all the locations where the cumulative sum revisits 0\n",
    "        position = numpy.where(cumulative_sum == 0)[0]\n",
    "        # For this identify all the cycles\n",
    "        cycles = []\n",
    "        for pos in range(len(position) - 1):\n",
    "            # Add this cycle to the list of cycles\n",
    "            cycles.append(cumulative_sum[position[pos]:position[pos + 1] + 1])\n",
    "        num_cycles = len(cycles)\n",
    "\n",
    "        state_count = []\n",
    "        for cycle in cycles:\n",
    "            # Determine the number of times each cycle visits each state\n",
    "            state_count.append(([len(numpy.where(cycle == state)[0]) for state in x_values]))\n",
    "        state_count = numpy.transpose(numpy.clip(state_count, 0, 5))\n",
    "\n",
    "        su = []\n",
    "        for cycle in range(6):\n",
    "            su.append([(sct == cycle).sum() for sct in state_count])\n",
    "        su = numpy.transpose(su)\n",
    "\n",
    "        piks = ([([self.get_pik_value(uu, state) for uu in range(6)]) for state in x_values])\n",
    "        inner_term = num_cycles * numpy.array(piks)\n",
    "        chi = numpy.sum(1.0 * (numpy.array(su) - inner_term) ** 2 / inner_term, axis=1)\n",
    "        p_values = ([spc.gammaincc(2.5, cs / 2.0) for cs in chi])\n",
    "        return p_values\n",
    "\n",
    "    def get_pik_value(self, k, x):\n",
    "        \"\"\"\n",
    "        This method is used by the random_excursions method to get expected probabilities\n",
    "        \"\"\"\n",
    "        if k == 0:\n",
    "            out = 1 - 1.0 / (2 * numpy.abs(x))\n",
    "        elif k >= 5:\n",
    "            out = (1.0 / (2 * numpy.abs(x))) * (1 - 1.0 / (2 * numpy.abs(x))) ** 4\n",
    "        else:\n",
    "            out = (1.0 / (4 * x * x)) * (1 - 1.0 / (2 * numpy.abs(x))) ** (k - 1)\n",
    "        return out\n",
    "\n",
    "    def random_excursions_check(self):\n",
    "        \"\"\"\n",
    "        This method is used to check the random_excursions method is working as expected\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        expected = [0.844143, 0.786868, 0.216235, 0.783283]\n",
    "        p_values = []\n",
    "        data_sets = [\"pi\", \"e\", \"sqrt2\", \"sqrt3\"]\n",
    "        for ds in data_sets:\n",
    "            data = self.load_test_data(ds)[:1000000]\n",
    "            p_values.append(self.random_excursions(data)[4])\n",
    "        self.generic_checker(\"Random Excursions Test\", expected, self.random_excursions, p_values)\n",
    "\n",
    "    def random_excursions_variant(self, bin_data):\n",
    "        \"\"\"\n",
    "        Note that this description is taken from the NIST documentation [1]\n",
    "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
    "\n",
    "        The focus of this test is the total number of times that a particular state is visited (i.e., occurs) in a\n",
    "        cumulative sum random walk. The purpose of this test is to detect deviations from the expected number of visits\n",
    "        to various states in the random walk. This test is actually a series of eighteen tests (and conclusions), one\n",
    "        test and conclusion for each of the states: -9, -8, , -1 and +1, +2, , +9.\n",
    "\n",
    "        :param bin_data: a binary string\n",
    "        :return: the P-value\n",
    "        \"\"\"\n",
    "        int_data = numpy.zeros(len(bin_data))\n",
    "        for i in range(len(bin_data)):\n",
    "            int_data[i] = int(bin_data[i])\n",
    "        sum_int = (2 * int_data) - numpy.ones(len(int_data))\n",
    "        cumulative_sum = numpy.cumsum(sum_int)\n",
    "\n",
    "        li_data = []\n",
    "        for xs in sorted(set(cumulative_sum)):\n",
    "            if numpy.abs(xs) <= 9:\n",
    "                li_data.append([xs, len(numpy.where(cumulative_sum == xs)[0])])\n",
    "\n",
    "        j = self.get_frequency(li_data, 0) + 1\n",
    "        p_values = []\n",
    "        for xs in range(-9, 9 + 1):\n",
    "            if not xs == 0:\n",
    "                den = numpy.sqrt(2 * j * (4 * numpy.abs(xs) - 2))\n",
    "                p_values.append(spc.erfc(numpy.abs(self.get_frequency(li_data, xs) - j) / den))\n",
    "        return p_values\n",
    "\n",
    "    def get_frequency(self, list_data, trigger):\n",
    "        \"\"\"\n",
    "        This method is used by the random_excursions_variant method to get frequencies\n",
    "        \"\"\"\n",
    "        frequency = 0\n",
    "        for (x, y) in list_data:\n",
    "            if x == trigger:\n",
    "                frequency = y\n",
    "        return frequency\n",
    "\n",
    "    def random_excursions_variant_check(self):\n",
    "        \"\"\"\n",
    "        This method is used to check the random_excursions_variant method is working as expected\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        expected = [0.760966, 0.826009, 0.566118, 0.155066]\n",
    "        p_values = []\n",
    "        data_sets = [\"pi\", \"e\", \"sqrt2\", \"sqrt3\"]\n",
    "        for ds in data_sets:\n",
    "            data = self.load_test_data(ds)[:1000000]\n",
    "            p_values.append(self.random_excursions_variant(data)[8])\n",
    "        self.generic_checker(\"Random Excursions Variant Test\", expected, self.random_excursions, p_values)\n",
    "\n",
    "class BinaryMatrix:\n",
    "    def __init__(self, matrix, rows, cols):\n",
    "        \"\"\"\n",
    "        This class contains the algorithm specified in the NIST suite for computing the **binary rank** of a matrix.\n",
    "        :param matrix: the matrix we want to compute the rank for\n",
    "        :param rows: the number of rows\n",
    "        :param cols: the number of columns\n",
    "        :return: a BinaryMatrix object\n",
    "        \"\"\"\n",
    "        self.num_rows = rows\n",
    "        self.num_cols = cols\n",
    "        self.matrix = matrix\n",
    "        self.m = min(rows, cols)\n",
    "\n",
    "    def compute_rank(self, verbose=False):\n",
    "        \"\"\"\n",
    "        This method computes the binary rank of self.matrix\n",
    "        :param verbose: if this is true it prints out the matrix after the forward elimination and backward elimination\n",
    "        operations on the rows. This was used to testing the method to check it is working as expected.\n",
    "        :return: the rank of the matrix.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Original Matrix\\n\", self.matrix)\n",
    "\n",
    "        i = 0\n",
    "        while i < self.m - 1:\n",
    "            if self.matrix[i][i] == 1:\n",
    "                self.perform_row_operations(i, True)\n",
    "            else:\n",
    "                found = self.find_unit_element_swap(i, True)\n",
    "                if found == 1:\n",
    "                    self.perform_row_operations(i, True)\n",
    "            i += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Intermediate Matrix\\n\", self.matrix)\n",
    "\n",
    "        i = self.m - 1\n",
    "        while i > 0:\n",
    "            if self.matrix[i][i] == 1:\n",
    "                self.perform_row_operations(i, False)\n",
    "            else:\n",
    "                if self.find_unit_element_swap(i, False) == 1:\n",
    "                    self.perform_row_operations(i, False)\n",
    "            i -= 1\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Final Matrix\\n\", self.matrix)\n",
    "\n",
    "        return self.determine_rank()\n",
    "\n",
    "    def perform_row_operations(self, i, forward_elimination):\n",
    "        \"\"\"\n",
    "        This method performs the elementary row operations. This involves xor'ing up to two rows together depending on\n",
    "        whether or not certain elements in the matrix contain 1's if the \"current\" element does not.\n",
    "        :param i: the current index we are are looking at\n",
    "        :param forward_elimination: True or False.\n",
    "        \"\"\"\n",
    "        if forward_elimination:\n",
    "            j = i + 1\n",
    "            while j < self.num_rows:\n",
    "                if self.matrix[j][i] == 1:\n",
    "                    self.matrix[j, :] = (self.matrix[j, :] + self.matrix[i, :]) % 2\n",
    "                j += 1\n",
    "        else:\n",
    "            j = i - 1\n",
    "            while j >= 0:\n",
    "                if self.matrix[j][i] == 1:\n",
    "                    self.matrix[j, :] = (self.matrix[j, :] + self.matrix[i, :]) % 2\n",
    "                j -= 1\n",
    "\n",
    "    def find_unit_element_swap(self, i, forward_elimination):\n",
    "        \"\"\"\n",
    "        This given an index which does not contain a 1 this searches through the rows below the index to see which rows\n",
    "        contain 1's, if they do then they swapped. This is done on the forward and backward elimination\n",
    "        :param i: the current index we are looking at\n",
    "        :param forward_elimination: True or False.\n",
    "        \"\"\"\n",
    "        row_op = 0\n",
    "        if forward_elimination:\n",
    "            index = i + 1\n",
    "            while index < self.num_rows and self.matrix[index][i] == 0:\n",
    "                index += 1\n",
    "            if index < self.num_rows:\n",
    "                row_op = self.swap_rows(i, index)\n",
    "        else:\n",
    "            index = i - 1\n",
    "            while index >= 0 and self.matrix[index][i] == 0:\n",
    "                index -= 1\n",
    "            if index >= 0:\n",
    "                row_op = self.swap_rows(i, index)\n",
    "        return row_op\n",
    "\n",
    "    def swap_rows(self, row_one, row_two):\n",
    "        \"\"\"\n",
    "        This method just swaps two rows in a matrix. Had to use the copy package to ensure no memory leakage\n",
    "        :param row_one: the first row we want to swap and\n",
    "        :param row_two: the row we want to swap it with\n",
    "        :return: 1\n",
    "        \"\"\"\n",
    "        temp = copy.copy(self.matrix[row_one, :])\n",
    "        self.matrix[row_one, :] = self.matrix[row_two, :]\n",
    "        self.matrix[row_two, :] = temp\n",
    "        return 1\n",
    "\n",
    "    def determine_rank(self):\n",
    "        \"\"\"\n",
    "        This method determines the rank of the transformed matrix\n",
    "        :return: the rank of the transformed matrix\n",
    "        \"\"\"\n",
    "        rank = self.m\n",
    "        i = 0\n",
    "        while i < self.num_rows:\n",
    "            all_zeros = 1\n",
    "            for j in range(self.num_cols):\n",
    "                if self.matrix[i][j] == 1:\n",
    "                    all_zeros = 0\n",
    "            if all_zeros == 1:\n",
    "                rank -= 1\n",
    "            i += 1\n",
    "        return rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is some experimentation with converting our ciphertext bytes to bits and dropping the leading '0b'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'HtoKljOT9dU7InuKWQMA7xh4DLUHj8nx6D3UByRTIjc/ne67VR6dA+TK+ArAaEI5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AES_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b1001000011101000110111101001011011011000110101001001111010101000011100101100100010101010011011101001001011011100111010101001011010101110101000101001101010000010011011101111000011010000011010001000100010011000101010101001000011010100011100001101110011110000011011001000100001100110101010101000010011110010101001001010100010010010110101001100011001011110110111001100101001101100011011101010110010100100011011001100100010000010010101101010100010010110010101101000001011100100100000101100001010001010100100100110101'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(bin(int.from_bytes(AES_list[0], byteorder='big')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'110101010010010100010101100001010000010111001001000001001010110100101101010100001010110100000101100100001101100101001001010110001101110011011001100101011011100010111101100011011010100100100101010100010100100111100101000010010101010011001101000100001101100111100001101110001110000110101001001000010101010100110001000100001101000110100001111000001101110100000101001101010100010101011101001011011101010110111001001001001101110101010101100100001110010101010001001111011010100110110001001011011011110111010001001000'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying each NIST test from r4nd0m's class functions (declared above) in following chunks\n",
    "Initializing class, then feeding single ciphertext binary value into each test... will likely need to feed ciphertext list into each function within a loop and then append the resulting p-value to a pandas series for plotting and review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng_tester = RandomnessTester(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monobit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062915064446396926"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.monobit(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Frequency test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23947323997465111"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.block_frequency(example_binary_string, block_size=64)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Runs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2290659704251233e-07"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.independent_runs(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Run of Ones test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2615424466696743e-05"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.longest_runs(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Rank Transformation test --> SAME VALUE EVERY TIME?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039104615860550376"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.matrix_rank(example_binary_string, matrix_size=16)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral (Discrete Fourier Transform) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda2\\envs\\Py3\\lib\\site-packages\\ipykernel\\__main__.py:621: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91908450296730204"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.spectral(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Overlapping Patterns test --> ALWAYS RETURNING SAME VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993062051306455"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.non_overlapping_patterns(example_binary_string, pattern=\"000000001\", num_blocks=8)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping Patterns test --> GETTING nan VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda2\\envs\\Py3\\lib\\site-packages\\ipykernel\\__main__.py:737: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.overlapping_patterns(example_binary_string, pattern_size=9, block_size=1032)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal test --> ALWAYS -1 VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.universal(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Complexity test --> ALWAYS -1 VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.linear_complexity(example_binary_string, block_size=500)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343789576471877"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.serial(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Entropy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.approximate_entropy(example_binary_string, pattern_length=16)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Sums test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0748321246812029"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_value = rng_tester.cumulative_sums(example_binary_string, method=\"forward\")\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Excursions test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99767176622636278"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_values = rng_tester.random_excursions(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Excursions Variant test --> ALWAYS RETURNING SAME VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0748321246812029"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_binary_string = str(bin(int.from_bytes(AES_list[0], byteorder=sys.byteorder))[2:])\n",
    "p_values = rng_tester.random_excursions_variant(example_binary_string)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
